## 机器学习课程

![image-20211015151123680](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2021-10/image-20211015151123680.png)

推荐菜菜的sklearn课程。这应该是我找到的最系统，最通俗易懂、实践性最强、教学讲解最好的网络课程，非常适用新手入门和回看复习。这里有部分课件(链接: https://pan.baidu.com/s/1AZ5h_uDKMBpxNvPIeASRBQ 提取码: osw8)

之前一直觉得当一名调包侠不好，直接调包肯定理解不好原理，所以一直拒绝Sklearn包，直到面试的时候才发现自己机器学习原理的欠缺，好多知识和公式并没有真正理解到位。更为致命的是压根不会用，不知道机器学习的流程是啥，有哪些的特征处理方法，哪些特征构造方法等等。

直到看到了菜菜老师的这门机器学习课程，非常系统，在这个自己学习探索阶段能够学到这样系统的课程是多么的幸福，比自己乱七八糟搜索来的知识系统的多！

正好也恶补一下吧。都是要还滴！

![image-20211012145229123](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2021-10/image-20211012145229123.png)

## 数据挖掘流程

1. 获取数据
2. 数据处理
3. 特征工程
4. 建模
5. 验证
6. 上线

### Sklearn中的数据处理和特征工程

skearn中的两大板块都是关于数据处理和特征工程的，分别是降维模块，和预处理模块。

> 模块preprocessing：几乎包含数据预处理的所有内容
> 模块Impute：填补缺失值专用
> 模块feature_selection：包含特征选择的各种方法的实践
> 模块decomposition：包含降维算法

![image-20220416162239887](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2022-04/image-20220416162239887.png)

## 1. 数据处理

![image-20211011170149135](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2021-10/image-20211011170149135.png)

以梯度和矩阵为核心的算法，例如逻辑回归，支持向量机，神经网络等，这些算法一定要进行无量纲化，加快收敛速度。而在距离模型，比如k近邻，k-Means，无量纲化可以帮助我们提升模型精度。而在树模型中，没有无量纲化也会达到较好的效果。

### 1.1 无量纲化

#### 1.1.1 归一化 preprocessing.MinMaxScaler

按照一下公式进行归一化，计算后的值域范围为【0，1】
$$
x^{*}=\frac{x-\min (x)}{\max (x)-\min (x)}
$$

```python
from sklearn.preprocessing import MinMaxScaler
# 实例化
scaler = MinMaxScaler()

# 在所有数据集上进行fit
scaler.fit(data)

# transform 利用fit好的scaler对data_train 进行压缩
scaler.transform(data_train)

# fit_transform 也可以一次搞定
scaler.fit_transform(x)

# 逆归一化
scaler.inverse_transform(x)

# 当数据量很大的时候，用 partial_fit 作为训练接口
```

#### 1.1.2 标准化 preprocessing.StandardScaler

进行标准化，标准化后的值域范围为 $[-\infty,\infty]$  
$$
x^{*}=\frac{x-\mu}{\sigma}
$$

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(x)
scaler.mean_
scaler.scale_
```
#### 1.1.3 其他无量纲化方式

![image-20220416165123523](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2022-04/image-20220416165123523.png)

### 1.2 缺失值处理

- impute.SimpleImputer

  ```python
  sklearn.impute.SimpleImputer(missing_values=nan,strategy='mean',fill_value=None,verbose=0,copy=True)
  ```

  ![image-20220417094230780](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2022-04/image-20220417094230780.png)

  ```python
  from sklearn.impute import SimpleImputer
  
  # 默认均值填补
  imp_mean = SimpleImputer()
  # 中位数策略
  imp_median = SimpleImputer(strategy="median")
  # 0填补
  imp_0 = SimpleImputer(strategy="constant",fill_value=0)
  
  imp_0.fit_transform(x)
  ```


  ![image-20220417101441194](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2022-04/image-20220417101441194.png)

### 1.3 处理分类数据：类别编码

- 标签编码，对标签列进行编码，所以只能是一维数据。

```python
from sklearn.preprocessing import LabelEncoder
data.iloc[:,-1] = LabelEncoder().fit_transform(data.iloc[:,-1])
```

- 特征编码，对特征进行编码，允许矩阵。

```python
from sklearn.preprocessing import OrdinalEncoder
# 返回所有分类变量的 有限个类别
OrdinalEncoder().fit(data.iloc[1:]).categories_

# fit_transform
data.iloc[:,-1] = OrdinalEncoder().fit_transform(data.iloc[:,-1])
```

-  one-hot encoder 独热编码

```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(categories='auto').fit(x)
res = encoder.transform(x)
```

![image-20220417105432684](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2022-04/image-20220417105432684.png)

### 1.4 处理连续型特征
#### 1.4.1 二值化

二值化就是将数据设置为0和1，比如把年龄分为未成年和成年人。
```python
from sklearn.preprocessing import Binarizer
X = data.loc['Age'].values.reshape(-1,1)

new_x = Binarizer(threshold=18).fit_transform(X)
```
#### 1.4.2 分箱
分箱即使将连续型变量分为阶段分类，比如将年龄分为儿童，青少年，中年，老年。
```python
# preprocessing.KBinsDiscretizer
# n_bins 分类个数，默认5
# encode 编码方式， 默认one-hot，选择有original
# strategy 分箱策略
```
## 2. 特征工程

特征工程是利用数据所在领域的相关知识来构建特征，使得机器学习算法发挥其最佳的过程。它是机器学习中的一个基本应用，实现难度大且代价高。采用自动特征工程方法可以省去采用人工特征工程的需求。

> Andrew Ng 说“挖掘特征是困难、费时且需要专业知识的事，应用机器学习其实基本上是在做特征工程。”
>
> 理解数据是非常重要的。没有充足的数据，合适的特征，再强大的模型结构也无法得到满意的输出。正如业界常说的一句话“Garbage in，garbage out.”对于一个机器学习问题，数据和特征汪往往决定了结果的上限，而模型、算法的选择和优化则是在逐步接近这个上限。
### 2.1 特征选择
#### 2.1.1 方差过滤
方差越小，信息含量肯定小，所以过滤掉方差小的变量。这种也一般适用于分类变量，连续型变量不适用。
```python
from sklearn.feature_selection import VarianceThreshold
# VarianceThreshold(阈值).fit_transform()
```

#### 2.1.2 相关性过滤

1. 卡方统计过滤

   卡方过滤是专门针对离散型数据的相关性过滤，即分类问题。计算**非负特征**与标签之间的相关关系。一般用`feature_selection.chi2`结合`SelectKBest`	选择分数最高的选择器。

  ```python
  from sklearn.ensemble import RandomForestClassifier as RFC
  from sklearn.model_selection import cross_val_score
  from sklearn.feature_selection import chi2
  from sklearn.feature_selection import SelectKBest
  xfschi = SelectKBest(chi2,k=300).fit_transform(X,y)
  cross_val_score(RFC(n_estimators=10,random_state=0),xfschi,y,cv=5).mean()
  ```

   但是其中的这个特征保留k的个数怎么确定呢，卡方检验是检验两组数据的差异，原假设是两组数据相互独立。卡方检验统计量的p值如果小于0.05，两组数据就是相关，拒绝原假设。


   可以用chi2直接计算出卡方统计值和p值。

  ```python
  chivalue,pvalue = chi2(x,y)
  ```

2. F 检验（ANOVA）

   方差齐性检验，包含分类检验和回归检验两类。追求p值小于显著性水平。

   ```python
   from sklearn.feature_selection import f_classif
   from sklearn.feature_selection import f_regresstion
   ```
   
3. 互信息 

   追求互信息值大于0

   ```python
   from sklearn.feature_selection import mutual_info_classif as MIC
   from sklearn.feature_selection import mutual_info_regression as MIR
   ```

#### 2.2.3 模型嵌入法过滤特征

   嵌入法是一种让算法自己决定使用哪些特征的方法，即特征选择和算法训练同时进行。但是当大量特征都对模型有贡献，并且贡献值不一的时候，需要使用一种准则来判定，哪些特征需要保留，哪些需要剔除。

```python
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import RandomForestClassifier as RFC

# 实例化 随机森林
RFC_ = RFC(n_estimators=10,random_state=0)

X_embedded = SelectFromModel(RFC_,threshold=0.005).fit_transform(X,y)
#两个重要参数 estimator threshold
# 任何具有coef_ 
```

#### 2.2.4 包装法

使用特征子集来进行训练模型，这个模型也不是最后我们要用的模型，而是某种特殊的专门的数据挖掘算法。这个算法最典型的是递归特征消除法，RFE。包装法是比较好用的一种特征选取方法，比较高效。

```python
from sklearn.feature_selection import RFE
RFC_ = RFE(n_estimators=10, ramdom_state=0) # 随机森林
selector = RFE(RFC_,n_features_to_select=340,step=50).fit(X,y)

# selector.support_ # 特征是否被选中
# selector.ranking_  # 特征重要性排序
```

### 2.2特征创造

一些降维算法，比如PCA，他们是用现有特征生成了新的特征，这些方法称之为特征创造。

![image-20211011195419431](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2021-10/image-20211011195419431.png)

