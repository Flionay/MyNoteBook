## 机器学习课程

![image-20211015151123680](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2021-10/image-20211015151123680.png)

推荐菜菜的sklearn课程。这应该是我找到的最系统，最通俗易懂、实践性最强、教学讲解最好的网络课程，非常适用新手入门和回看复习。这里有部分课件(链接: https://pan.baidu.com/s/1AZ5h_uDKMBpxNvPIeASRBQ 提取码: osw8)

之前一直觉得当一名调包侠不好，直接调包肯定理解不好原理，所以一直拒绝Sklearn包，直到面试的时候才发现自己机器学习原理的欠缺，好多知识和公式并没有真正理解到位。更为致命的是压根不会用，不知道机器学习的流程是啥，有哪些的特征处理方法，哪些特征构造方法等等。

直到看到了菜菜老师的这门机器学习课程，非常系统，在这个自己学习探索阶段能够学到这样系统的课程是多么的幸福，比自己乱七八糟搜索来的知识系统的多！

正好也恶补一下吧。都是要还滴！

![image-20211012145229123](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2021-10/image-20211012145229123.png)

## 数据挖掘流程

1. 获取数据
2. 数据处理
3. 特征工程
4. 建模
5. 验证
6. 上线

### Sklearn中的数据处理和特征工程

skearn中的两大板块都是关于数据处理和特征工程的，分别是降维模块，和预处理模块。

> 模块preprocessing：几乎包含数据预处理的所有内容
> 模块Impute：填补缺失值专用
> 模块feature_selection：包含特征选择的各种方法的实践
> 模块decomposition：包含降维算法

![image-20220416162239887](http://pic.angyi.online/uPic/2022-04/image-20220416162239887.png)

## 1. 数据处理

![image-20211011170149135](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2021-10/image-20211011170149135.png)

以梯度和矩阵为核心的算法，例如逻辑回归，支持向量机，神经网络等，这些算法一定要进行无量纲化，加快收敛速度。而在距离模型，比如k近邻，k-Means，无量纲化可以帮助我们提升模型精度。而在树模型中，没有无量纲化也会达到较好的效果。

### 1.1 无量纲化

#### 1.1.1 归一化 preprocessing.MinMaxScaler

按照一下公式进行归一化，计算后的值域范围为【0，1】
$$
x^{*}=\frac{x-\min (x)}{\max (x)-\min (x)}
$$

```python
from sklearn.preprocessing import MinMaxScaler
# 实例化
scaler = MinMaxScaler()

# 在所有数据集上进行fit
scaler.fit(data)

# transform 利用fit好的scaler对data_train 进行压缩
scaler.transform(data_train)

# fit_transform 也可以一次搞定
scaler.fit_transform(x)

# 逆归一化
scaler.inverse_transform(x)

# 当数据量很大的时候，用 partial_fit 作为训练接口
```

#### 1.1.2 标准化 preprocessing.StandardScaler

进行标准化，标准化后的值域范围为 $[-\infty,\infty]$  
$$
x^{*}=\frac{x-\mu}{\sigma}
$$

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(x)
scaler.mean_
scaler.scale_
```
#### 1.1.3 其他无量纲化方式

![image-20220416165123523](http://pic.angyi.online/uPic/2022-04/image-20220416165123523.png)

### 1.2 缺失值处理

- impute.SimpleImputer

  ```python
  sklearn.impute.SimpleImputer(missing_values=nan,strategy='mean',fill_value=None,verbose=0,copy=True)
  ```

  ![image-20220417094230780](http://pic.angyi.online/uPic/2022-04/image-20220417094230780.png)

  ```python
  from sklearn.impute import SimpleImputer
  
  # 默认均值填补
  imp_mean = SimpleImputer()
  # 中位数策略
  imp_median = SimpleImputer(strategy="median")
  # 0填补
  imp_0 = SimpleImputer(strategy="constant",fill_value=0)
  
  imp_0.fit_transform(x)
  ```


  ![image-20220417101441194](http://pic.angyi.online/uPic/2022-04/image-20220417101441194.png)

### 1.3 类别编码

- 标签编码，对标签列进行编码，所以只能是一维数据。

```python
from sklearn.preprocessing import LabelEncoder
data.iloc[:,-1] = LabelEncoder().fit_transform(data.iloc[:,-1])
```

- 特征编码，对特征进行编码，允许矩阵。

```python
from sklearn.preprocessing import OrdinalEncoder
# 返回所有分类变量的 有限个类别
OrdinalEncoder().fit(data.iloc[1:]).categories_

# fit_transform
data.iloc[:,-1] = OrdinalEncoder().fit_transform(data.iloc[:,-1])
```

-  one-hot encoder 独热编码

```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(categories='auto').fit(x)
res = encoder.transform(x)
```

![image-20220417105432684](http://pic.angyi.online/uPic/2022-04/image-20220417105432684.png)

### 1.4 处理连续型特征：二值化 分段

s

## 3. 特征工程

特征工程是利用数据所在领域的相关知识来构建特征，使得机器学习算法发挥其最佳的过程。它是机器学习中的一个基本应用，实现难度大且代价高。采用自动特征工程方法可以省去采用人工特征工程的需求。

> Andrew Ng 说“挖掘特征是困难、费时且需要专业知识的事，应用机器学习其实基本上是在做特征工程。”
>
> 理解数据是非常重要的。

![image-20211011195419431](https://pic-1300286858.cos.ap-nanjing.myqcloud.com/uPic/2021-10/image-20211011195419431.png)

